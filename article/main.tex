\documentclass[a4paper, 11pt]{article}
% \usepackage{ae,lmodern}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[USenglish]{babel}
\usepackage[margin=3cm]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section] % Number within sec ?
% \newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{observation}[theorem]{Observation}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
% \newtheorem*{remark*}{Remark}
% \theoremstyle{definition}
% \newtheorem{problem}{Problem}
% \newtheorem{openproblem}{Open Problem}

\newcommand{\NN}{\mathbb{N}}%
\newcommand{\ZZ}{\mathbb{Z}}%
\newcommand{\Sbb}{\mathbb{S}}%
\newcommand{\Cc}{\mathcal{C}}%
\newcommand{\Gg}{\mathcal{G}}%
\newcommand{\Ff}{\mathcal{F}}%
\newcommand{\Ss}{\mathcal{S}}%
\newcommand{\eps}{\varepsilon}%
\newcommand{\epsm}{\eps^{-1}}%
\newcommand{\bit}{\{0,1\}}%
\DeclareMathOperator*{\poly}{poly}

\newcommand{\Omegat}[1]{\widetilde{\Omega}\left( #1 \right)}%
\newcommand{\Ot}[1]{\widetilde{O}\left( #1 \right)}%

\newcommand{\Poly}{\textsf{P}}%
\newcommand{\NP}{\textsf{NP}}%
\newcommand{\NTIME}{\textsf{NTIME}}%
\newcommand{\coNTIME}{\textsf{coNTIME}}%
\newcommand{\SAT}{\textsf{SAT}}%
\newcommand{\ParSAT}{\ensuremath\bigoplus\textsf{SAT}}%
\newcommand{\SharpSAT}{\#\textsf{SAT}}%
\newcommand{\NAND}{\textsf{NAND}}%
\newcommand{\ND}{\textsf{NAND-DEPTH}}%
\newcommand{\NDL}[1]{\ensuremath\ND[ #1 \log n]}%

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\title{Uniform formula lower bounds for finding and counting satisfiable assignments}
\author{Gabriel Bathie, Ryan Williams}
\begin{document}
\maketitle

\begin{abstract}
\end{abstract}


List of things to do:
\begin{itemize}
	\item Improve Spira/Brent to show that a $c \log n$ depth 
	lower bound implies an $n^{c-\eps}$ size lower bound?
	\item Show that this bound is optimal w.r.t. these rules?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Motivation: understanding complexity. Explicit lower bounds : programs, circuits, formulas.
Uniformity.

Related work:
- Original line of work : \cite{fortnow2000time,fortnow2005time}
- Main line of work \cite{williams2006inductive,williams2007time,williams2013alternation} and its dramatic resolution \cite{buss2015limits}.
- Broader classes \cite{mudigonda2020time}

Best known formula lower bounds for languages (functions?) in NP: 
\begin{itemize}
	\item $\Omegat{n^3}$ (for both uniform and non-uniform formulas) for Andreev's function \cite{hastad1998shrinkage}\todo{check source} in the De Morgan basis $\{\wedge, \vee, \neg\}$.
	\item $\Omega(n^2/\log n)$ in the full binary basis (Nechiporuk)
	\item $n^{\Theta(\log n)}$ for monotone formulas (formulas over the $\{\wedge, \vee\}$ basis).
\end{itemize}

\subsection{Results overview}

We first study \NAND{} formulas. 
The \NAND{} basis is rather expressive: Andreev's function has \NAND{} formulas of depth $(3+o(1)) \log n$ (and therefore of size $\Ot{n^3}$), which matches the lower bound for the De Morgan Basis.


\begin{theorem}
	For any $c < 4 \cos(\pi/7) \simeq 3.603$, \SAT{} does not have \NAND{} formulas of depth $(c + o(1)) \log n$.
\end{theorem}

\todo[inline]{Prove all of the following.

After checking \cite{sergeev2019relation}, this is probably incorrect...}
\begin{lemma}
	For any \NAND{} formula on $n$ inputs of size $n^c$ and any $\eps > 0$, 
	there exists an equivalent \NAND{} formula of depth $(c+\eps) \log n$.
\end{lemma}

\begin{corollary}
	For any $c < 4 \cos(\pi/7)$, \SAT{} does not have \NAND{} formulas of \textbf{size} $n^{c + o(1)}$.
\end{corollary}

\begin{theorem} (??)
	With our rules, we cannot do better than $4 \cos(\pi/7)$.
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Definitions}

\subsection{Uniform formulas}
A family of formulas

In this work, we focus on formulas with depth $d(n) = (c + o(1))\log n$, for some $c > 1$.

\begin{definition}[``Usual'' polylog-time uniform formulas]
	A family of formulas $(\varphi_n)_{n \ge 1}$ of depth $(c + o(1))\log n$ 
	is \textit{polylog-time uniform} if there exists a machine $A_\varphi$
	such that for every $n$ and every $b\in\bit^{\leq (c + o(1))\log n}$,
	$A_\varphi(b, n)$ outputs a description of the gate at position $b$ in $\varphi_n$ in time $\log^{O(1)} n$.
\end{definition}

Here, the position of a gate is given by a bitstring of length at most $(c + o(1))\log n$ 
that describes the path to follow to reach that gate from the root, 
with $0$ meaning ``go to left child'' and $1$ ``go to right child''.


In this work, we consider a stronger model of uniform formulas, 
where the descriptor machine $A_\varphi$ has random access to the input $x$ 
at which we wish to evaluate the formula, but is still limited to polylogarithmic time.
\begin{definition}[Input-aware polylog-time uniform formulas]\todo{is this a good name?}\label{def:unif}
	A family of formulas $(\varphi_n)_{n \ge 1}$ of depth $(c + o(1))\log n$ is \textit{polylog-time uniform}
	if there exists a \textbf{RAM} machine $B_\varphi$
	such that for every $n$, every $x\in\bit^n$ and every $b\in\bit^{\leq (c + o(1))\log n}$,
	$B_\varphi(x, b, n)$ outputs a description of the gate at position $b$ in $\varphi_n$ in time $\log^{O(1)} n$.
\end{definition}
Notice that this model supersedes the previous one: 
$A_\varphi$ satisfies the conditions of Definition~\ref{def:unif}, 
but does not use its random access to the input, 
therefore the lower bounds that we give against model also hold for the usual one.

Moreover, this definition allows for an efficient simulation of uniform formulas by RAM machines, 
due to the negligible overhead.
Indeed, for every $c > 1$, we have $\ND[c \log n] \subseteq TS[n^c]$.

We will see the need for this stronger definition in \todo{ref}, 
where we need to give $O(\log n)$ bits of information to the descriptor
to adaptively choose a subformula.

Uniform \NAND{}/alternating formulas. Specific model, comparison with the usual model.

\subsection{Quantified/Alternating computation}

We now introduce ``quantified'' complexity classes, which extend alternating classes 
by adding a ``parity'' quantifier.

Given a complexity class $\Cc$ and constants $k, (a_i)_{i\leq k}$, 
we consider \textit{quantified} complexity
class $(Q_1~n^{a_1})\ldots(Q_k~n^{a_k})~\Cc$, 
where $Q_i$ is one of $\forall, \exists$ or $\oplus$.
A computation in a quantified complexity class is defined as follows:
\begin{definition}[Quantified computation]
	A language $L$ is in $(Q_1~n^{a_1})\ldots(Q_k~n^{a_k})~\Cc$ 
	is defined by $k$ RAM machines $A_1, \ldots, A_k$ and a $\Cc$ machine $M$
	such that, given an input $x$ of length $n$:
	for every $i \le k$, $A_{i}$ takes as input $x_i$ along with $y_i$, 
	a string of $n^{a_{i} + o(1)}$ nondeterministic bits,
	runs in time $n^{a_{i} + o(1)}$ and outputs a string $x_{i+1}$ of length at most $n^{a_{i} + o(1)}$, 
	with the convention that $x_0 := x$.
	The output of the last stage, $x_{k+1}$, is passed to the machine $M$. 

	The computation accepts $x$ \textit{starting from stage $i$} if either:
	\begin{itemize}
		\item $i = k+1$ and $M$ accepts $x_{k+1}$, 
		\item $Q_i$ is $\exists$, and there exists a $y_i$ such that the computation
		accepts $x_{i+1}$ starting from stage $i+1$, 
		\item $Q_i$ is $\forall$, and for every $y_i$, the computation
		accepts $x_{i+1}$ starting from stage $i+1$, 
		\item $Q_i$ is $\bigoplus$, the number of $y_i$ such that the computation
		accepts $x_{i+1}$ starting from stage $i+1$ is odd. 
	\end{itemize}

	An input $x$ is in $L$ if the computation $x$ accepts starting from stage 1.
\end{definition}

\subsection{Overview of the methodology}

The general methodology used in this paper to obtain lower bounds
extends the one used in~\cite{mudigonda2020time}.

To prove that \SAT{} does not have formulas of depth less than $c\log n$, 
we reason by contradiction.
First, we assume that \SAT{} has such formulas, and the strong \NP-completeness of \SAT{}
allows us to deduce that the same is holds for all of $\NTIME[n]$, 
a result referred to as the ``Slowdown Lemma''.
\begin{lemma}[Slowdown Lemma]
	Let $\Ff$ be an expressive\todo{define} class of formulas, and let $c > 1$.
	If \SAT{} is in $\Ff[c \log n]$\todo{define},
	then $\NTIME[n] \cup \coNTIME[n] \subseteq \Ff[c \log n]$.
\end{lemma}
\todo[inline]{talk about the issue with input size}

We also show how to speed-up (or rather, reduce the depth of) computations by adding quantifiers, 
using various ``Speedup Lemmas''. 
For example, for NAND formulas (which are the same as alternating AND/OR formulas), we have the following:
\begin{lemma}[Speedup Lemma]
	For every $c > 0, x \leq c$, we have:
	\[\textsf{NAND-depth}[c \log n] \subseteq (\exists n^{x/2}) (\forall n^1) \textsf{NAND-depth}[(c-x) \log n]\]
\end{lemma}

We then combine multiple application of these lemmas with various parameters,
with the goal of contradicting a known hierarchy theorem.
For example, we can prove that SAT does not have NAND formulas 
of depth less than $(2-\eps) \log n$ for any $\eps > 0$ with the following proof.
Assume that $\SAT\in \textsf{NAND-depth}[c \log n]$.
Then, we have
\begin{flalign*}
	NTIME[n^{2}]
		&\subseteq \NDL{2c}	& \text{Slowdown Lemma}\\
		&\subseteq (\exists n^{c})(\forall n^1)\NDL{0}& \text{Speedup Lemma with param. } x = 2c\\
		&\subseteq (\exists n^{c})\coNTIME[n]	& \\
		&\subseteq (\exists n^{c})\NDL{c}	& \text{Slowdown Lemma}\\
		&\subseteq \NTIME[n^c]	&
\end{flalign*}
For $c < 2$, this contradicts the Nondeterministic Time Hierarchy Theorem.
In practice, we use (integer) linear programming to find the best order of application
of the rules, and the best parameters to use.

We proceed similarly with properties of \ParSAT{} and \SharpSAT{}
to prove results for fomulas with XOR gates.

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of thm}
Speedup Rule for Alternating formulas.

Slowdown Rule from algorithms for SAT assumptions:
\begin{lemma}
	Let $\Ff$ be a class of formulas closed under composition that can simulate projections in constant depth.
	If $\SAT{}\in \Ff[c \log n]$, then $\NTIME[n] \subseteq \Ff[c \log n]$.
\end{lemma}
\begin{proof}
	This follows from the fact that $\SAT{}$ is \NP-complete under uniform poly-log time first-order projections.
\end{proof}

Can we say the same for $\ParSAT$ and $\SharpSAT$?

How to get the contradiction given the slowdown rule for $c < 4\cos(\pi /7)$.

\subsection{Improving Brent/Spira}
\todo[inline]{Prove this}
Useful starting point : Size-Depth Tradeoffs for Boolean Formulae (Bonet, Buss).

Remark: we must focus on the case when the input formula is a \NAND{} formula.
Otherwise, we prove a much stronger result.
Maybe prove the stronger result with a $2+\eps$ factor? Not very useful though.
If we can go below 2, we improve something.
%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of optimality}
\todo[inline]{Prove this}


%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plain}
\bibliography{biblio.bib}

\end{document}
