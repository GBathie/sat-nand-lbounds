\documentclass[a4paper, 11pt]{article}
% \usepackage{ae,lmodern}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[USenglish]{babel}
\usepackage[margin=3cm]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section] % Number within sec ?
% \newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{property}[theorem]{Property}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{observation}[theorem]{Observation}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
% \newtheorem*{remark*}{Remark}
% \theoremstyle{definition}
% \newtheorem{problem}{Problem}
% \newtheorem{openproblem}{Open Problem}

\newcommand{\NN}{\mathbb{N}}%
\newcommand{\ZZ}{\mathbb{Z}}%
\newcommand{\Sbb}{\mathbb{S}}%
\newcommand{\Cc}{\mathcal{C}}%
\newcommand{\Gg}{\mathcal{G}}%
\newcommand{\Ff}{\mathcal{F}}%
\newcommand{\Ss}{\mathcal{S}}%
\newcommand{\eps}{\varepsilon}%
\newcommand{\epsm}{\eps^{-1}}%
\newcommand{\bit}{\{0,1\}}%
\DeclareMathOperator*{\poly}{poly}

\newcommand{\Omegat}[1]{\widetilde{\Omega}\left( #1 \right)}%
\newcommand{\Ot}[1]{\widetilde{O}\left( #1 \right)}%

\newcommand{\Poly}{\textsf{P}}%
\newcommand{\NP}{\textsf{NP}}%
\newcommand{\TIME}{\textsf{TIME}}%
\newcommand{\NTIME}{\textsf{NTIME}}%
\newcommand{\coNTIME}{\textsf{coNTIME}}%
\newcommand{\SAT}{\textsf{SAT}}%
\newcommand{\ParSAT}{\ensuremath\bigoplus\textsf{SAT}}%
\newcommand{\SharpSAT}{\#\textsf{SAT}}%
\newcommand{\NAND}{\textsf{NAND}}%
\newcommand{\ND}{\textsf{NDepth}}%
\newcommand{\NDL}[1]{\ND[ #1 \log n]}%

\newcommand{\todohere}{\todo[inline]{TODO}}%

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\title{Uniform formula lower bounds for finding and counting satisfiable assignments}
\author{Gabriel Bathie, Ryan Williams}
\begin{document}
\maketitle

\begin{abstract}
\end{abstract}


List of things to do:
\begin{itemize}
	\item Improve Spira/Brent to show that a $c \log n$ depth 
	lower bound implies an $n^{c-\eps}$ size lower bound?
	\item Show that this bound is optimal w.r.t. these rules?
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Motivation: understanding complexity. Explicit lower bounds : programs, circuits, formulas.
Uniformity.

Related work:
- Original line of work : \cite{fortnow2000time,fortnow2005time}
- Main line of work \cite{williams2006inductive,williams2007time,williams2013alternation} and its dramatic resolution \cite{buss2015limits}.
- Broader classes \cite{mudigonda2020time}

Best known formula lower bounds for languages (functions?) in NP: 
\begin{itemize}
	\item $\Omegat{n^3}$ (for both uniform and non-uniform formulas) for Andreev's function \cite{hastad1998shrinkage}\todo{check source} in the De Morgan basis $\{\wedge, \vee, \neg\}$.
	\item $\Omega(n^2/\log n)$ in the full binary basis (Nechiporuk)
	\item $n^{\Theta(\log n)}$ for monotone formulas (formulas over the $\{\wedge, \vee\}$ basis).
\end{itemize}

\subsection{Results overview}

We first study \NAND{} formulas. 
The \NAND{} basis is rather expressive: Andreev's function has \NAND{} formulas of depth $(3+o(1)) \log n$ (and therefore of size $\Ot{n^3}$), which matches the lower bound for the De Morgan Basis.


\begin{theorem}
	For any $c < 4 \cos(\pi/7) \simeq 3.603$, \SAT{} does not have \NAND{} formulas of depth $(c + o(1)) \log n$.
\end{theorem}

\todo[inline]{Prove all of the following.

After checking \cite{sergeev2019relation}, this is probably incorrect...}
\begin{lemma}
	For any \NAND{} formula on $n$ inputs of size $n^c$ and any $\eps > 0$, 
	there exists an equivalent \NAND{} formula of depth $(c+\eps) \log n$.
\end{lemma}

\begin{corollary}
	For any $c < 4 \cos(\pi/7)$, \SAT{} does not have \NAND{} formulas of \textbf{size} $n^{c + o(1)}$.
\end{corollary}

\begin{theorem} (??)
	With our rules, we cannot do better than $4 \cos(\pi/7)$.
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Definitions}

\subsection{Uniform formulas}
A family of formulas

In this work, we focus on formulas with depth $d(n) = (c + o(1))\log n$, for some $c > 1$.

\begin{definition}[``Usual'' polylog-time uniform formulas]
	A family of formulas $(\varphi_n)_{n \ge 1}$ of depth $(c + o(1))\log n$ 
	is \textit{polylog-time uniform} if there exists a machine $A_\varphi$
	such that for every $n$ and every $b\in\bit^{\leq (c + o(1))\log n}$,
	$A_\varphi(b, n)$ outputs a description of the gate at position $b$ in $\varphi_n$ in time $\log^{O(1)} n$.
\end{definition}

Here, the position of a gate is given by a bitstring of length at most $(c + o(1))\log n$ 
that describes the path to follow to reach that gate from the root, 
with $0$ meaning ``go to left child'' and $1$ ``go to right child''.


In this work, we consider a stronger model of uniform formulas, 
where the descriptor machine $A_\varphi$ has random access to the input $x$ 
at which we wish to evaluate the formula, but is still limited to polylogarithmic time.
\begin{definition}[Input-aware polylog-time uniform formulas]\todo{is this a good name?}\label{def:unif}
	A family of formulas $(\varphi_n)_{n \ge 1}$ of depth $(c + o(1))\log n$ is \textit{polylog-time uniform}
	if there exists a \textbf{RAM} machine $B_\varphi$
	such that for every $n$, every $x\in\bit^n$ and every $b\in\bit^{\leq (c + o(1))\log n}$,
	$B_\varphi(x, b, n)$ outputs a description of the gate at position $b$ in $\varphi_n$ in time $\log^{O(1)} n$.
\end{definition}
Notice that this model supersedes the previous one: 
$A_\varphi$ satisfies the conditions of Definition~\ref{def:unif}, 
but does not use its random access to the input, 
therefore the lower bounds that we give against model also hold for the usual one.

Moreover, this definition allows for an efficient simulation of uniform formulas by RAM machines, 
due to the negligible overhead.
Indeed, for every $c > 1$, we have $\ND[c \log n] \subseteq TS[n^c]$.

We will see the need for this stronger definition in \todo{ref}, 
where we need to give $O(\log n)$ bits of information to the descriptor
to adaptively choose a subformula.

Uniform \NAND{}/alternating formulas. Specific model, comparison with the usual model.

\subsection{Quantified/Alternating computation}

We now introduce ``quantified'' complexity classes, which extend alternating classes 
by adding a ``parity'' quantifier.

Given a complexity class $\Cc$ and constants $k, (a_i)_{i\leq k}$, 
we consider \textit{quantified} complexity
class $(Q_1~n^{a_1})\ldots(Q_k~n^{a_k})~\Cc$, 
where $Q_i$ is one of $\forall, \exists$ or $\oplus$.
A computation in a quantified complexity class is defined as follows:
\begin{definition}[Quantified computation]
	A language $L$ is in $(Q_1~n^{a_1})\ldots(Q_k~n^{a_k})~\Cc$ 
	is defined by $k$ RAM machines $A_1, \ldots, A_k$ and a $\Cc$ machine $M$
	such that, given an input $x$ of length $n$:
	for every $i \le k$, $A_{i}$ takes as input $x_i$ along with $y_i$, 
	a string of $n^{a_{i} + o(1)}$ nondeterministic bits,
	runs in time $n^{a_{i} + o(1)}$ and outputs a string $x_{i}$ of length at most $n^{a_{i} + o(1)}$, 
	with the convention that $x_0 := x$.
	The output of the last stage, $x_{k}$, is passed to the machine $M$. 

	The computation accepts $x$ \textit{starting from stage $i$} if either:
	\begin{itemize}
		\item $i = k+1$ and $M$ accepts $x_{k}$, 
		\item $Q_i$ is $\exists$, and there exists a $y_i$ such that the computation
		accepts $x_{i}$ starting from stage $i+1$, 
		\item $Q_i$ is $\forall$, and for every $y_i$, the computation
		accepts $x_{i}$ starting from stage $i+1$, 
		\item $Q_i$ is $\bigoplus$, the number of $y_i$ such that the computation
		accepts $x_{i}$ starting from stage $i+1$ is odd. 
	\end{itemize}

	An input $x$ is in $L$ if the computation $x$ accepts starting from stage 1.
\end{definition}
\todo[inline]{allow $O(\log n)$ quantifiers ?}

\subsection{Overview of the methodology}

The general methodology used in this paper to obtain lower bounds
extends the one used in~\cite{mudigonda2020time}.

To prove that \SAT{} does not have formulas of depth less than $c\log n$, 
we reason by contradiction.
First, we assume that \SAT{} has such formulas, and the strong \NP-completeness of \SAT{}
allows us to deduce that the same is holds for all of $\NTIME[n]$, 
a result referred to as the ``Slowdown rule''.
\begin{lemma}[Slowdown rule]
	% Let $\Ff$ be an expressive\todo{define} class of formulas, and let $c > 1$.
	If \SAT{} is in $\NDL{c}$ for some $c>0$,
	then $\NTIME[n] \cup \coNTIME[n] \subseteq \NDL{c}$.
\end{lemma}
\todo[inline]{That's not the rule...}

We also show how to speed-up (or rather, reduce the depth of) computations by adding quantifiers, 
using various ``Speedup rules''. 
For example, for NAND formulas (which are the same as alternating AND/OR formulas), we have the following:
\begin{lemma}[Speedup rule]
	For every $c > 0, x \leq c$, we have:
	\[\textsf{NAND-depth}[c \log n] \subseteq (\exists n^{x/2}) (\forall n^1) \textsf{NAND-depth}[(c-x) \log n]\]
\end{lemma}

We then combine multiple application of these lemmas with various parameters,
with the goal of contradicting a known hierarchy theorem.
Assuming that $\NTIME[n] \subseteq \NDL[c]$ for some $n$, we obtain the following hierarchy theorem
for NAND formulas, as a corollary of the Nondeterministic Time Hierarchy Theorem:
\begin{theorem}\label{thm:nandh}
	If there exists $c > 0$ such that $\NTIME[n] \subseteq \NDL{c}$, 
	then for all $b > a > 0$, we have
	\[\NDL{a} \subsetneq \NDL{b}.\] 
\end{theorem}

For example, we can prove that SAT does not have NAND formulas 
of depth less than $2.8284 \log n$ with the following proof.
Assume that $\SAT\in \textsf{NAND-depth}[c \log n]$ for some $c > 0$.
Then, we have
\begin{flalign*}
	\NDL{4}
		&\subseteq (\exists n)(\forall n)\NDL{2}& \text{Speedup rule with param. } x = 2\\
		&\subseteq (\exists n)\NDL{c}	& \text{Slowdown rule}\\
		&\subseteq \NDL{c^2/2}	& \text{Slowdown rule}
\end{flalign*}
For $c^2/2  < 4 \leftrightarrow c < 2\sqrt{2} \simeq 2.8284\ldots$, this contradicts Theorem~\ref{thm:nandh}.

In practice, we use (integer) linear programming to find the best order of application
of the rules, and the best parameters to use.

%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of main result}

\subsection{Speedup and Slowdowns}
We start by discussion the Speedup rule for Alternating formulas.

\begin{lemma}[Speedup rule]\label{lemma:speedup}
	For every $d > 0$ and $0 \ge x \ge d$, we have
	\begin{flalign*}
	\NDL{d} &\subseteq (\exists n^{x/2}) (\forall \frac{x}{2}\log n) \NDL{d-x}\text{ and}\\
	\NDL{d} &\subseteq (\forall n^{x/2}) (\exists \frac{x}{2}\log n) \NDL{d-x}
	\end{flalign*}
\end{lemma}

The intuitive idea behind this lemma is that the only information needed to know that an OR gate evaluates
to 1 is that one of its children evaluates to 1. 
We apply this idea to every OR gate in the first $x \log n$ levels of the formula,
and then use a universal quantifier to handle the remaining AND gates.

The role of the existential quantifier is to guess for every OR gate in the first $(x/2)\log n$ levels,
which of its children evaluates to 1, and we only evaluate the corresponding subformula.
Moreover, making this guess reduces the number of OR gates that we will evaluate
(this number doubles every two levels, instead of doubling at every level), 
therefore we only need to guess $O(n^{x/2})$ bits. 

We can then eliminate OR gates and replace them with their selected child.
We are left with a formula starting with $(x/2)\log n$ levels of AND gates, 
followed by OR/AND formulas of depth $(d-x + o(1)) \log n$.
The main formula evaluate to 1 if and only if for every of these $O(n^{x/2})$
smaller formulas evaluates to true: 
we can check this using a universal quantifiers, 
which requires $O(\frac{x}{2}\log n)$ bits, and then running an $\NDL{d-x}$ computation.

Finally, notice that the definition of alternating computation
requires that there exists a \textit{single} machine $M$ that runs the
final stage of computation \textit{for every} possible choice of nondeterministic bits.
This is where we use the strong notion of uniformity (from Definition~\ref{def:unif}), where the descriptor machine
has random access to the input: giving $M$ access to (a few) bits of the input
allows us to adapt its behavior depending on the nondeterministic bits. 

\begin{proof}[Proof of Lemma~\ref{lemma:speedup}]
	We prove the result for $\exists\forall$ computations, 
	the result for $\forall\exists$ computations follows from the fact that $\NDL{d}$ is closed
	under complementation.
	
	Let $L\in\NDL{d}$, let be $M : (x,i,n) \mapsto g$ be the a descriptor machine for $L$,
	and let $x$ be an input of length $n$.
	
	We now construct a machine $M'$ that describes $\NDL{d-x}$-formulas,
	such that an $\exists\forall$ computation with $M'$ as its last stage accepts $L$.
	On an input $x$

	We describe how to build bit strings $y$ of length $n^{x/2}$ and
	\todohere 
\end{proof}


\begin{corollary}\label{cor:speedup}
	For every $d > 0$, we have
	\[\NDL{d} \subseteq \NTIME[n^{d/2}] \cap \coNTIME[n^{d/2}].\]
\end{corollary}
\begin{proof}
	Applying Lemma~\ref{lemma:speedup} with $x = d$, we obtain
	$\NDL{d} \subseteq (\exists n^{d/2}) (\forall \frac{d}{2}\log n) \NDL{0}$.
	Now, using an exhaustive search over the $n^{d/2}$ bit strings of length $\frac{d}{2}\log n$
	followed by a deterministic $n^{o(1)}$ computation,
	we get
	$\NDL{d} \subseteq (\exists n^{d/2}) \TIME[n^{d/2}]$.
\end{proof}


We now discuss
Slowdown rule from algorithms for SAT assumptions:
\begin{lemma}[Slowdown rule]\label{lemma:slowdown}
	If $\SAT{}\in \NDL{c}$, then for every $d \ge 1$, $\NTIME[n^d] \cup \coNTIME[n^d] \subseteq \NDL{c\cdot d}$.
\end{lemma}

A key idea for the proof of Lemma~\ref{lemma:slowdown} 
is the fact that any language in $\NTIME[n]$ can
be reduced to $\SAT{}$ via uniform poly-log time first-order projections, 
with instances of size $n$ reduced to formulas of size $n^{1+o(1)}$.
Intuitively, a first order projection is a depth 0 circuit, 
i.e. each output bit is either a constant (0 or 1),
an input $x_i$ or its negation, $\neg x_i$.
For a more in-depth exposition of first-order projections,
see for example~\cite[End of Sec.~3]{allender1997first}.
\begin{proof}[Proof of Lemma~\ref{lemma:slowdown}]
	We first prove that $\SAT{}\in \NDL{c}$ implies that $\NTIME[n] \subseteq \NDL{c}$,
	then use a padding argument to show that $\forall d\ge 1, \NTIME[n^d] \subseteq \NDL{c\cdot d}$,
	and the result follows since $\NDL{c\cdot d}$ is closed under complement.

	Let $L\in\NTIME[n]$. 
	As stated above, $L$ is Karp-reducible to \SAT{} via
	uniform poly-log time first-order projections, 
	\todo{ref for this? Folklore?}
	with instances of size $n$ reduced to formulas of size $n^{1+o(1)}$.
	Now, notice that the composition of a NAND formula of depth $d$ with a first order projection
	is also a NAND formula of depth $d$: it only consists in relabeling leaves of the formula.
	Poly-log time uniformity is also preserved. 
	Therefore, we can use $(c+o(1)) \log n$-depth NAND formulas for \SAT{} on $n^{1+o(1)}$
	inputs to decide $L$ by composing them with the first order projection; 
	the resulting formula has size $(c+o(1)) \log n^{1+o(1)} = (c+o(1)) \log n$,
	therefore $L\in\NDL{c}$.

	We now use a padding argument to lift this result to $\NTIME[n^d]$.
	Let $d>1$, let $L\in \NTIME[n^d]$ and let $M$ be a nondeterministic machine that decides $L$
	in time $n^{d+o(1)}$.
	Consider the padded language $L' = \{x1^{|x|^d - |x|} \mid x\in L\}$.
	Given an input $y$ of length $m$, we can decide whether $y\in L'$ in time 
	$m^{1+o(1)}$ as follows:
	\begin{itemize}
		\item if $y$ is not of the form $x1^{|x|^d - |x|}$ for some $x$, reject $y$.
		This can be done in time $O(m)$.
		\item otherwise, $y = x1^{|x|^d - |x|}$. Run $M$ on $x$, and accept $y$ 
		if and only it accepts $x$. This takes time $|x|^{d+o(1)} = m^{1+o(1)}$.
	\end{itemize}
	This implies $L'$ is in $\NTIME[n]$, which in turn implies that $L'\in\NDL{c}$.
	We can then use the formula descriptor $A$ for $L'$ 
	to describe formulas of depth $(c + o(1))\log \left(n^{d+o(1)}\right) = (c\cdot d + o(1))\log n$ for $L$.
	On input $x,b,n$, the descriptor machine $B$ for $L$  
	calls $A$ on $x, b, n^d$.
	If $A$ output a gate type or a constant, $B$ outputs the same information.
	If $A$ outputs a literal $x_i^*$, $B$ outputs $x_i^*$ if $i \le n$, and 1 otherwise.
\end{proof}

We need to be careful when applying the slowdown lemma to alternating classes:
the $i+1$-th computation stage takes as input a string of length $m = n^{a_i}$, not $n$.
Since the previous result only holds for $\NTIME[n^d], d \ge 1$, 
we need to take into
account the edge case where the running time of the $i+1$-th
stage is sublinear in the size of its input.
We have the following:
\begin{corollary}[Extended Slowdown rule]
	If $\SAT{}\in \NDL{c}$, then for every $d > 1$, we have:
	\[\ldots (Q~n^{a}) (\neg Q~n^b) \NDL{d}
	\subseteq \ldots (Q~n^{a}) \NDL{c\cdot\max(d/2, a, b)}.\]
	\todo{fix the $d/2$}
\end{corollary}
\begin{proof}
	Without loss of generality, assume that $Q = \forall$, and therefore $\neg Q = \exists$.
	In that case, we have $(\neg Q~n^b) \NDL{d} \subseteq \NTIME[n^{\max(d, b)}]$,
	since evaluating a formula of depth $d \log n$ can be done in deterministic time
	$n^{d + o(1)}$.

	Now, consider the $\NTIME[n^{\max(d, b)}]$ language $L$ that correspond to the last stage of the alternating 
	computation, and its corresponding nondeterministic machine $M$. 
	It takes as input a string of length $m = n^{a}$, and its runtime, as a function of $m$, 
	is $m^{\max(d, b)/a}$.
	We apply the Slowdown rule to $M$. There are two possible cases:
	\begin{itemize}
		\item if $\max(d, b)/a < 1$, then we have $L \in \NTIME[m^{\max(d, b)/a}] \subseteq \NTIME[m]
		\subseteq \ND[c \log m] \subseteq \NDL{c \cdot a}$.
		Since  $\max(d, b) < a$, we have $a = \max(d, a, b)$ and therefore 
		$\NDL{c \cdot a} = \NDL{c\cdot\max(d, a, b)}$.
		\item otherwise, $\max(d, b) \ge a$, and applying the slowdown rule yields
		$L \in \NTIME[m^{\max(d, b)/a}] =  \NTIME[n^{\max(d, b)}] \subseteq \NDL{c \cdot \max(d, a, b)}$.
	\end{itemize}
\end{proof}


How to get the contradiction given the slowdown rule for $c < 4\cos(\pi /7)$.

\subsection{Improving Brent/Spira}
\todo[inline]{Prove this}
Useful starting point : Size-Depth Tradeoffs for Boolean Formulae (Bonet, Buss).

Remark: we must focus on the case when the input formula is a \NAND{} formula.
Otherwise, we prove a much stronger result.
Maybe prove the stronger result with a $2+\eps$ factor? Not very useful though.
If we can go below 2, we improve something.
%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of optimality}
\todo[inline]{Prove this}


%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plain}
\bibliography{biblio.bib}

\end{document}
